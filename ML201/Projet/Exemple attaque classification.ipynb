{"cells":[{"cell_type":"markdown","metadata":{"id":"AZhlLxX-l_5m"},"source":["#TP deep learning sous attaque adversaire (2024)\n","####Adrien Chan-Hon-Tong\n","####TP réalisé à partir de résultats de Pol Labarbarie\n","\n","\n","L'objet de ce TP est de démontrer\n","- la faciliter de produire des attaques adversaires \"white box\" sur des réseaux naifs quelles soient invisibles ou par patch\n","- mais que cela est beaucoup plus dur sur un réseau robustifier (cas invisible)\n","- ou encore qu'il est beaucoup plus difficile de produire des attaques \"transferable\"\n","\n","## generalité\n","Commençons par télécharger 10 images d'imagenet."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"g6FDb1CEFqXa","executionInfo":{"status":"ok","timestamp":1738017676643,"user_tz":-60,"elapsed":2015,"user":{"displayName":"Hugo","userId":"07649574654278319349"}},"outputId":"a45b052a-9f47-4898-9968-6baa692aa8dc","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["rm: cannot remove 'sample_data': Is a directory\n","--2025-01-27 22:41:14--  https://httpmail.onera.fr/21/9f6c7025f0680226eb94c7a73cc4290dG7fRIu/data.zip\n","Resolving httpmail.onera.fr (httpmail.onera.fr)... 144.204.16.9\n","Connecting to httpmail.onera.fr (httpmail.onera.fr)|144.204.16.9|:443... connected.\n","HTTP request sent, awaiting response... 404 Not Found\n","2025-01-27 22:41:15 ERROR 404: Not Found.\n","\n","unzip:  cannot find or open data.zip, data.zip.zip or data.zip.ZIP.\n","sample_data\n"]}],"source":["!rm -f *\n","!wget https://httpmail.onera.fr/21/9f6c7025f0680226eb94c7a73cc4290dG7fRIu/data.zip\n","!unzip data.zip\n","!ls"]},{"cell_type":"markdown","metadata":{"id":"arTqlxWjK1UQ"},"source":["Affichons les : les 5 premières sont des \"avions\" et les 5 suivantes des \"requins\""]},{"cell_type":"code","execution_count":4,"metadata":{"id":"x7OtnMFzl_HU","executionInfo":{"status":"error","timestamp":1738017658562,"user_tz":-60,"elapsed":349,"user":{"displayName":"Hugo","userId":"07649574654278319349"}},"outputId":"9d2c6e31-b56f-420c-a6c7-651a19025cc9","colab":{"base_uri":"https://localhost:8080/","height":406}},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"[Errno 2] No such file or directory: '1.png'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-cb65216e7561>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-cb65216e7561>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/io/image.py\u001b[0m in \u001b[0;36mread_image\u001b[0;34m(path, mode, apply_exif_orientation)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_exif_orientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_exif_orientation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/io/image.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_torchbind_op_overload\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_must_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_call_overload_packet_from_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: [Errno 2] No such file or directory: '1.png'"]}],"source":["import torch\n","import torchvision\n","import matplotlib.pyplot as plt\n","\n","x = [torchvision.io.read_image(str(i)+\".png\") for i in range(10)]\n","x = torch.stack(x,dim=0).float()/255\n","\n","visu = torchvision.utils.make_grid(x, nrow=5)\n","plt.imshow(visu.permute(1, 2, 0).numpy())\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z9I5vYlpLRAF","executionInfo":{"status":"ok","timestamp":1736245675544,"user_tz":-60,"elapsed":6358,"user":{"displayName":"","userId":""}},"outputId":"08a3ee8e-2292-40eb-ef72-325a768e21e6","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n","100%|██████████| 171M/171M [00:01<00:00, 117MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["tensor([403, 405, 404, 405, 404,   4,   3,   3,   3,   2])\n"]}],"source":["SHARK, PLANE = [2, 3, 4], [403, 404, 405]\n","normalize = torchvision.transforms.Normalize(\n","    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",")\n","resnet = torchvision.models.resnet101(\n","    weights=torchvision.models.ResNet101_Weights.IMAGENET1K_V1\n",").eval()\n","\n","with torch.no_grad():\n","    z = resnet(normalize(x))\n","    _,z = z.max(1)\n","    print(z)"]},{"cell_type":"markdown","metadata":{"id":"h8Ti-1roOsJ7"},"source":["On voit que le réseau classe correctement ces images.\n","\n","## Attaque standard \"white box\"\n","\n","On va maintenant rajouter à ces images un petit bruit \"invisible\" pour l'oeil mais perturbant pour le réseau."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"idDfEQKFFejn","executionInfo":{"status":"ok","timestamp":1736245808021,"user_tz":-60,"elapsed":115042,"user":{"displayName":"","userId":""}},"outputId":"7a354c83-2448-40c6-ac4a-c4438796d3f8","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["0 0.04686766862869263\n","1 3.540823459625244\n","2 9.229753494262695\n","3 15.51185417175293\n","4 22.443988800048828\n","5 28.232580184936523\n","6 33.313053131103516\n","7 38.62725830078125\n","8 39.327423095703125\n","9 44.154701232910156\n"]}],"source":["y = torch.Tensor([403, 405, 404, 405, 404,   4,   3,   3,   3,   2]).long()\n","cefunction = torch.nn.CrossEntropyLoss()\n","attaque = torch.nn.Parameter(torch.zeros(x.shape))\n","optimizer = torch.optim.SGD([attaque],lr=0.005)\n","for i in range(10):\n","  z = resnet(normalize(x+attaque))\n","  ce = cefunction(z,y)\n","  print(i,float(ce))\n","  ce = -ce # on veut MAXIMISER la cross entropy puisqu'on attaque\n","  optimizer.zero_grad()\n","  ce.backward()\n","  attaque.grad = attaque.grad.sign()\n","  optimizer.step()\n","  with torch.no_grad():\n","      # l'attaque doit être invisible\n","      attaque = torch.clamp(attaque, -10./255,+10./255)\n","\n","      # attaque+x doit être entre 0 et 1\n","      lowbound = -x\n","      uppbound = 1-x\n","      attaque = lowbound*(attaque<lowbound).float() + uppbound*(attaque>uppbound).float() + attaque *(attaque>=lowbound).float()*(attaque<=uppbound).float()\n","\n","  attaque = torch.nn.Parameter(attaque.clone())\n","  optimizer = torch.optim.SGD([attaque],lr=0.005)"]},{"cell_type":"markdown","metadata":{"id":"ZmMDfE1AR6hx"},"source":["80% des images \"x+attaque\" sont désormais mal classées ! (et le label de toutes à changer)\n","Pourtant, l'attaque ne se voit pas :"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W236tA8DSGHu"},"outputs":[],"source":["with torch.no_grad():\n","    z = resnet(normalize(x))\n","    _,z = z.max(1)\n","    print(z)\n","    z = resnet(normalize(x+attaque))\n","    _,z = z.max(1)\n","    print(z)\n","\n","visu = torch.cat([x,x+attaque],dim=0)\n","visu = torchvision.utils.make_grid(visu, nrow=5)\n","plt.imshow(visu.permute(1, 2, 0).numpy())\n","plt.show()"]},{"cell_type":"markdown","source":["Comment est ce que c'est possible ? Les réseaux ne sont pas du tout lipschitziens..."],"metadata":{"id":"kR3NAbhIID13"}},{"cell_type":"code","source":["with torch.no_grad():\n","    resnet = torchvision.models.resnet101(\n","        weights=torchvision.models.ResNet101_Weights.IMAGENET1K_V1\n","    ).eval()\n","    resnet.fc = torch.nn.Identity()\n","    z = resnet(x)\n","    print(((z[0]-z[5])**2).sum())\n","    z_ = resnet(x+attaque)\n","    print(((z[0]-z_[0])**2).sum())"],"metadata":{"id":"zVA7QMbyJgOM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["On voit que la représentation de l'image 0 devient presque aussi lointaine à cause de l'attaque que la distance avec l'image 5 !\n","Alors que nous ne voyons même pas la différence !\n","\n","____________________________________________________________________________\n","=> retour aux slides (on revient ici après).\n","____________________________________________________________________________\n","\n","# Attaque standard par patch \"white box\"\n","Maintenant on va regarder la création d'un patch adversarial : pour rappel, le problème des bruits invisibles c'est l'impossibilité de les faire dans le monde physique et l'existance de défense -> deux choses que les patches peuvent bypasser.\n","\n","On va mettre un patch 36x36 en haut à gauche (remarquons que si le patch est juste noir, ça change rien)."],"metadata":{"id":"k59OChLKKXnf"}},{"cell_type":"code","source":["mask = torch.zeros(1,3,224,224)\n","mask[:,:,0:36,0:36] = 1\n","\n","resnet = torchvision.models.resnet101(\n","    weights=torchvision.models.ResNet101_Weights.IMAGENET1K_V1\n",").eval()\n","with torch.no_grad():\n","    z = resnet(normalize(x))\n","    _,z = z.max(1)\n","    print(z)\n","    z = resnet(normalize(x*(1-mask)))\n","    _,z = z.max(1)\n","    print(z)\n","\n","visu = torch.cat([x,x*(1-mask)],dim=0)\n","visu = torchvision.utils.make_grid(visu, nrow=5)\n","plt.imshow(visu.permute(1, 2, 0).numpy())\n","plt.show()"],"metadata":{"id":"0mdKRmHdS8Fz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["mais s'il est optimisé ?"],"metadata":{"id":"4sEsZnlaTjJL"}},{"cell_type":"code","source":["y = torch.Tensor([403, 405, 404, 405, 404,   4,   3,   3,   3,   2]).long()\n","cefunction = torch.nn.CrossEntropyLoss()\n","attaque = torch.nn.Parameter(torch.rand(1,3,224,224))\n","optimizer = torch.optim.SGD([attaque],lr=0.1)\n","for i in range(40):\n","  z = resnet(normalize(x*(1-mask)+mask*attaque))\n","  ce = cefunction(z,y)\n","  print(i,float(ce))\n","  ce = -ce # on veut MAXIMISER la cross entropy puisqu'on attaque\n","  optimizer.zero_grad()\n","  ce.backward()\n","  attaque.grad = attaque.grad.sign()\n","  optimizer.step()\n","  with torch.no_grad():\n","      # l'attaque doit être dans le domaine image\n","      attaque = torch.clamp(attaque, 0,1)\n","\n","  attaque = torch.nn.Parameter(attaque.clone())\n","  if i<20:\n","      optimizer = torch.optim.SGD([attaque],lr=0.1)\n","  else:\n","      optimizer = torch.optim.SGD([attaque],lr=0.05)\n","\n","with torch.no_grad():\n","    z = resnet(normalize(x))\n","    _,z = z.max(1)\n","    print(z)\n","    z = resnet(normalize(x*(1-mask) + attaque*mask))\n","    _,z = z.max(1)\n","    print(z)\n","\n","visu = torch.cat([x,x*(1-mask)+attaque*mask],dim=0)\n","visu = torchvision.utils.make_grid(visu, nrow=5)\n","plt.imshow(visu.permute(1, 2, 0).numpy())\n","plt.show()"],"metadata":{"id":"az8_ho5lLWbD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Des images ont vu leur label changé (c'est ici pas 100% mais c'est le MÊME patch pour toutes les images - et il n'est pas vraiment optimisé suffisamment longtemps).\n","\n","## Limites\n","\n","Ici on montre la facilité de faire une attaque **numérique** contre un réseau **naif** et **connu**.\n","Heureusement, la situation est très différente contre un réseau *défendu* ou *inconnu* ou quand l'attaque doit être *physiquement réalisable*.\n","\n","### Réseaux défendus\n","\n","On trouve très peu de réseaux défendus sur internet pour Imagenet (on trouve surtout des réseaux CIFAR et les rares qu'on peut trouver pour Imagenet comme dans le github https://github.com/MadryLab/robustness sont des réseaux custom).\n","Aussi, nous allons abandonnés nos avions/requins et faire des petites expériences sur CIFAR10.\n","\n","Commençons par apprendre un réseau sur CIFAR:"],"metadata":{"id":"JeoPFyyhldXS"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","\n","normalize = torchvision.transforms.Normalize(\n","    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",")\n","transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),normalize])\n","trainset = torchvision.datasets.CIFAR10(\n","    root=\"build\",\n","    train=True,\n","    download=True,\n","    transform=transform,\n",")"],"metadata":{"id":"P1kLcM0QXF6n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resnet = torchvision.models.resnet18(\n","    weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1\n",").eval()\n","resnet.fc = torch.nn.Linear(512,10)\n","\n","trainloader = torch.utils.data.DataLoader(\n","    trainset, batch_size=64, shuffle=True, num_workers=2\n",")\n","cefunction = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(resnet.parameters(), lr=0.0001)\n","meanloss = torch.zeros(50)\n","for i,(x,y) in enumerate(trainloader):\n","    z=resnet(x)\n","    loss = cefunction(z,y)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    with torch.no_grad():\n","        meanloss[i%50]=loss.clone()\n","        if i%50==49:\n","          print(float(meanloss.mean()))\n","    if i==1000:\n","        break"],"metadata":{"id":"MT3aTtf-XI1y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["vérifions que la perfo est pas trop mauvaise (très en dessous de l'état de l'art néanmoins car on a appris vraiment très très très peu) :"],"metadata":{"id":"HfSHsT0hfx2m"}},{"cell_type":"code","source":["testset = torchvision.datasets.CIFAR10(\n","    root=\"build\",\n","    train=False,\n","    download=True,\n","    transform=transform,\n",")\n","testloader = torch.utils.data.DataLoader(\n","    testset, batch_size=500, shuffle=True, num_workers=2\n",")\n","\n","with torch.no_grad():\n","    for x,y in testloader:\n","        z = resnet(x)\n","        _,z = z.max(1)\n","        good = (z==y).float().sum()\n","        print(float(good/5))\n","        break"],"metadata":{"id":"o-QLjDDLV1u_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["c'est pas \"terrible\" mais ça ira pour la preuve de concept...\n","\n","attaquons 10 images bien classée !"],"metadata":{"id":"tUVr78-ChjHn"}},{"cell_type":"code","source":["I = [i for i in range(500) if y[i]==z[i]]\n","I = I[0:10]\n","y,x=y[I],x[I]\n","#ces 10 là sont bien classées !\n","\n","cefunction = torch.nn.CrossEntropyLoss()\n","attaque = torch.nn.Parameter(torch.zeros(x.shape))\n","optimizer = torch.optim.SGD([attaque],lr=0.005)\n","for i in range(25):\n","  z = resnet(x+attaque)\n","  ce = cefunction(z,y)\n","  print(i,float(ce))\n","  ce = -ce # on veut MAXIMISER la cross entropy puisqu'on attaque\n","  optimizer.zero_grad()\n","  ce.backward()\n","  attaque.grad = attaque.grad.sign()\n","  optimizer.step()\n","  with torch.no_grad():\n","    # l'attaque doit être invisible\n","    attaque = torch.clamp(attaque, -10./255,+10./255)\n","\n","    # attaque+x doit être entre 0 et 1\n","    lowbound = -x\n","    uppbound = 1-x\n","    attaque = lowbound*(attaque<lowbound).float() + uppbound*(attaque>uppbound).float() + attaque *(attaque>=lowbound).float()*(attaque<=uppbound).float()\n","\n","  attaque = torch.nn.Parameter(attaque.clone())\n","  optimizer = torch.optim.SGD([attaque],lr=0.005)\n","\n","with torch.no_grad():\n","  z = resnet(x)\n","  _,z = z.max(1)\n","  print(z)\n","  z = resnet(x+attaque)\n","  _,z = z.max(1)\n","  print(z)\n","\n","visu = torch.cat([x,x+attaque],dim=0)\n","visu = torchvision.utils.make_grid(visu, nrow=5)\n","plt.imshow(visu.permute(1, 2, 0).numpy())\n","plt.show()"],"metadata":{"collapsed":true,"id":"xOFXzOiNhuwO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Bon même si on est pas à 10/10, on voit que le modèle (pourtant non convergé) est quand même très sensible...\n","\n","maintenant regardons si on apprend un modèle **robuste**."],"metadata":{"id":"EnTmtd70k34l"}},{"cell_type":"code","source":["torch.save(resnet,\"resnet.pth\")\n","resnetrobuste = torch.load(\"resnet.pth\") #force unrelated copy\n","\n","trainloader = torch.utils.data.DataLoader(\n","    trainset, batch_size=64, shuffle=True, num_workers=2\n",")\n","cefunction = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(resnetrobuste.parameters(), lr=0.0001)\n","meanloss = torch.zeros(50)\n","for i,(x,y) in enumerate(trainloader):\n","    #attack x, then update the weight to deal with the fact that z has been attacked\n","    attaque = torch.nn.Parameter(torch.zeros(x.shape))\n","    attackoptimizer = torch.optim.SGD([attaque],lr=0.001)\n","    for _ in range(10):\n","      z = resnet(x+attaque)\n","      ce = cefunction(z,y)\n","      ce = -ce # on veut MAXIMISER la cross entropy puisqu'on attaque\n","      optimizer.zero_grad()\n","      ce.backward()\n","      attaque.grad = attaque.grad.sign()\n","      optimizer.step()\n","\n","    #now attaque is frozen\n","    with torch.no_grad():\n","        attaque = torch.Tensor(attaque.clone())\n","\n","    z = resnetrobuste(x+attaque)\n","    loss = cefunction(z,y)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    with torch.no_grad():\n","        meanloss[i%50]=loss.clone()\n","        if i%50==49:\n","          print(float(meanloss.mean()))\n","\n","        if i%5==4:\n","          torch.save(resnetrobuste,\"tmp.pth\")\n","          resnet = torch.load(\"tmp.pth\") #update the network from which attack is crafted\n","    if i==400:\n","        break"],"metadata":{"id":"8m0QzqYwmoAy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["la performance sur les images \"normales\" devraient avoir baissée"],"metadata":{"id":"jMTb4MDy3AhR"}},{"cell_type":"code","source":["with torch.no_grad():\n","    for x,y in testloader:\n","        z = resnetrobuste(x)\n","        _,z = z.max(1)\n","        good = (z==y).float().sum()\n","        print(float(good/5))\n","        break"],"metadata":{"id":"svKd8WeP2_sb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["mais la performance devrait rester similaire sur des images attaquées"],"metadata":{"id":"TnEhBFWY3LPN"}},{"cell_type":"code","source":["I = [i for i in range(500) if y[i]==z[i]]\n","I = I[0:10]\n","y,x=y[I],x[I]\n","#ces 10 là sont bien classées !\n","\n","cefunction = torch.nn.CrossEntropyLoss()\n","attaque = torch.nn.Parameter(torch.zeros(x.shape))\n","optimizer = torch.optim.SGD([attaque],lr=0.005)\n","for i in range(25):\n","  z = resnetrobuste(x+attaque)\n","  ce = cefunction(z,y)\n","  print(i,float(ce))\n","  ce = -ce # on veut MAXIMISER la cross entropy puisqu'on attaque\n","  optimizer.zero_grad()\n","  ce.backward()\n","  attaque.grad = attaque.grad.sign()\n","  optimizer.step()\n","  with torch.no_grad():\n","    # l'attaque doit être invisible\n","    attaque = torch.clamp(attaque, -10./255,+10./255)\n","\n","    # attaque+x doit être entre 0 et 1\n","    lowbound = -x\n","    uppbound = 1-x\n","    attaque = lowbound*(attaque<lowbound).float() + uppbound*(attaque>uppbound).float() + attaque *(attaque>=lowbound).float()*(attaque<=uppbound).float()\n","\n","  attaque = torch.nn.Parameter(attaque.clone())\n","  optimizer = torch.optim.SGD([attaque],lr=0.005)\n","\n","with torch.no_grad():\n","  z = resnetrobuste(x)\n","  _,z = z.max(1)\n","  print(z)\n","  z = resnetrobuste(x+attaque)\n","  _,z = z.max(1)\n","  print(z)\n","\n","visu = torch.cat([x,x+attaque],dim=0)\n","visu = torchvision.utils.make_grid(visu, nrow=5)\n","plt.imshow(visu.permute(1, 2, 0).numpy())\n","plt.show()"],"metadata":{"id":"7XXYQ8jm3R1e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["On voit que le modèle est déjà plus robuste (alors qu'on a effectué que très très peu d'itération de robustification)...\n","\n","**De fait aujourd'hui, ce type d'apprentissage permet d'avoir une robustesse forte contre les attaques invisibles.**\n","\n","### Transferabilité\n","\n","Une des autres difficultés est d'attaquer un réseau inconnu : revenons à nos images d'avions et requins et recréons notre attaque invisible du début\n","\n"],"metadata":{"id":"Gtb-0_EGGvpk"}},{"cell_type":"code","source":["x = [torchvision.io.read_image(str(i)+\".png\") for i in range(10)]\n","x = torch.stack(x,dim=0).float()/255\n","y = torch.Tensor([403, 405, 404, 405, 404,   4,   3,   3,   3,   2]).long()\n","\n","normalize = torchvision.transforms.Normalize(\n","    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",")\n","resnet = torchvision.models.resnet101(\n","    weights=torchvision.models.ResNet101_Weights.IMAGENET1K_V1\n",").eval()\n","\n","cefunction = torch.nn.CrossEntropyLoss()\n","attaque = torch.nn.Parameter(torch.zeros(x.shape))\n","optimizer = torch.optim.SGD([attaque],lr=0.005)\n","for i in range(10):\n","  z = resnet(normalize(x+attaque))\n","  ce = cefunction(z,y)\n","  print(i,float(ce))\n","  ce = -ce # on veut MAXIMISER la cross entropy puisqu'on attaque\n","  optimizer.zero_grad()\n","  ce.backward()\n","  attaque.grad = attaque.grad.sign()\n","  optimizer.step()\n","  with torch.no_grad():\n","      # l'attaque doit être invisible\n","      attaque = torch.clamp(attaque, -10./255,+10./255)\n","\n","      # attaque+x doit être entre 0 et 1\n","      lowbound = -x\n","      uppbound = 1-x\n","      attaque = lowbound*(attaque<lowbound).float() + uppbound*(attaque>uppbound).float() + attaque *(attaque>=lowbound).float()*(attaque<=uppbound).float()\n","\n","  attaque = torch.nn.Parameter(attaque.clone())\n","  optimizer = torch.optim.SGD([attaque],lr=0.005)\n","\n","\n","with torch.no_grad():\n","    z = resnet(normalize(x))\n","    _,z = z.max(1)\n","    print(z)\n","    z = resnet(normalize(x+attaque))\n","    _,z = z.max(1)\n","    print(z)"],"metadata":{"id":"DOQ35ADdHxSF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["et regardons ce que donne cette attaque sur un autre réseau"],"metadata":{"id":"W5rbWXCQIjD6"}},{"cell_type":"code","source":["efficientnet = torchvision.models.efficientnet_b0(\n","    weights=torchvision.models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",").eval()\n","\n","with torch.no_grad():\n","    z = efficientnet(normalize(x))\n","    _,z = z.max(1)\n","    print(z)\n","    z = efficientnet(normalize(x+attaque))\n","    _,z = z.max(1)\n","    print(z)"],"metadata":{"id":"IXzhqphnIio3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["on voit que l'attaque n'a presque aucun effet !!!\n","\n","essayons de rendre l'attaque transferable en attaquant non pas la classification mais les features comme proposé par https://openaccess.thecvf.com/content_CVPR_2019/papers/Inkawhich_Feature_Space_Perturbations_Yield_More_Transferable_Adversarial_Examples_CVPR_2019_paper.pdf"],"metadata":{"id":"RCJhZL58I4Jj"}},{"cell_type":"code","source":["resnet = torchvision.models.resnet101(\n","    weights=torchvision.models.ResNet101_Weights.IMAGENET1K_V1\n",").eval()\n","resnet.fc = torch.nn.Identity()\n","with torch.no_grad():\n","  f_0 = resnet(normalize(x))\n","  f_0 = torch.stack([f_0[-1]]*5+[f_0[0]]*5,dim=0)\n","\n","attaque = torch.nn.Parameter(torch.zeros(x.shape))\n","optimizer = torch.optim.SGD([attaque],lr=0.005)\n","for i in range(10):\n","  f = resnet(normalize(x+attaque))\n","\n","  loss = ((f-f_0)**2).sum()\n","  print(i,float(loss))\n","  optimizer.zero_grad()\n","  loss.backward()\n","  attaque.grad = attaque.grad.sign()\n","  optimizer.step()\n","  with torch.no_grad():\n","      # l'attaque doit être invisible\n","      attaque = torch.clamp(attaque, -10./255,+10./255)\n","\n","      # attaque+x doit être entre 0 et 1\n","      lowbound = -x\n","      uppbound = 1-x\n","      attaque = lowbound*(attaque<lowbound).float() + uppbound*(attaque>uppbound).float() + attaque *(attaque>=lowbound).float()*(attaque<=uppbound).float()\n","\n","  attaque = torch.nn.Parameter(attaque.clone())\n","  optimizer = torch.optim.SGD([attaque],lr=0.005)\n","\n","\n","resnet = torchvision.models.resnet101(\n","    weights=torchvision.models.ResNet101_Weights.IMAGENET1K_V1\n",").eval()\n","with torch.no_grad():\n","    z = resnet(normalize(x))\n","    _,z = z.max(1)\n","    print(z)\n","    z = resnet(normalize(x+attaque))\n","    _,z = z.max(1)\n","    print(z)\n","\n","resnet = torchvision.models.resnet50(\n","    weights=torchvision.models.ResNet50_Weights.IMAGENET1K_V1\n",").eval()\n","with torch.no_grad():\n","    z = resnet(normalize(x))\n","    _,z = z.max(1)\n","    print(z)\n","    z = resnet(normalize(x+attaque))\n","    _,z = z.max(1)\n","    print(z)"],"metadata":{"id":"mY18N4lvJZeo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["On voit apparaitre une très légère transférabilité...\n","\n","Pour les attaques invisibles, il faudrait rajouter un générateur mais cela est difficilement démontrable sur google collab\n","\n","Pour aller plus loin sur la transferabilité des patches on pourrait tenter une attaque \"loss transport\" comme dans https://openreview.net/forum?id=nZP10evtkV\n","On peut néanmoins évaluer les patches produits."],"metadata":{"id":"o_R_ORbBvyqi"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","import matplotlib.pyplot as plt\n","\n","x = [torchvision.io.read_image(str(i)+\".png\") for i in range(10)]\n","x = torch.stack(x,dim=0).float()/255\n","\n","SHARK, PLANE = [2, 3, 4], [403, 404, 405]\n","normalize = torchvision.transforms.Normalize(\n","    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",")\n","resnet = torchvision.models.resnet101(\n","    weights=torchvision.models.ResNet101_Weights.IMAGENET1K_V1\n",").eval()\n","\n","S = 80\n","mask = torch.zeros(1,3,224,224)\n","mask[:,:,0:S,0:S] = 1\n","\n","attaque = torchvision.io.read_image(\"patch_bannane.png\").float()/255\n","attaque = torch.nn.functional.interpolate(attaque.view(1,3,297,295), size=(S,S))\n","tmp = torch.zeros(1,3,224,224)\n","tmp[:,:,0:S,0:S] = attaque\n","attaque = tmp\n","\n","resnet = torchvision.models.resnet101(\n","    weights=torchvision.models.ResNet101_Weights.IMAGENET1K_V1\n",").eval()\n","with torch.no_grad():\n","    z = resnet(normalize(x))\n","    _,z = z.max(1)\n","    print(z)\n","    z = resnet(normalize(x*(1-mask)))\n","    _,z = z.max(1)\n","    print(z)\n","    z = resnet(normalize(x*(1-mask) + mask*attaque))\n","    _,z = z.max(1)\n","    print(z)\n","\n","efficientnet = torchvision.models.efficientnet_b0(\n","    weights=torchvision.models.EfficientNet_B0_Weights.IMAGENET1K_V1\n",").eval()\n","with torch.no_grad():\n","    z = efficientnet(normalize(x))\n","    _,z = z.max(1)\n","    print(z)\n","    z = efficientnet(normalize(x*(1-mask)))\n","    _,z = z.max(1)\n","    print(z)\n","    z = efficientnet(normalize(x*(1-mask) + mask*attaque))\n","    _,z = z.max(1)\n","    print(z)\n","\n","visu = torch.cat([x,x*(1-mask),x*(1-mask)+mask*attaque ],dim=0)\n","visu = torchvision.utils.make_grid(visu, nrow=5)\n","plt.imshow(visu.permute(1, 2, 0).numpy())\n","plt.show()"],"metadata":{"id":"tjGOSAPlzAdc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["on a bien 1 patch (assez gros mais \"imprimable\") qui arrive à casser quelques images sur 2 réseaux différents !\n","\n","**==> c'est la fin de ce TP**"],"metadata":{"id":"4dLVbGTL2yqs"}}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/achanhon/coursdeeplearningcolab/blob/master/TP_ADVERSAIRE.ipynb","timestamp":1736245897325}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}